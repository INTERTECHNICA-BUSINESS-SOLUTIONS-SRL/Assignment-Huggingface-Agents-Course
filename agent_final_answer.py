# Copyright (c) Iuga Marin
# This file is part of the HuggingFace free AI Agents course assignment.
# It contains the implementation of a cached response handler for an AI agent, which formats intermediate answers into final responses.

import logging
from typing import Any, List, Tuple

from agent_basic_tooling import AgentBasicTooling
from langchain_core.messages import HumanMessage
from setup import get_final_answer_LLM


class AgentFinalAnswer():
    """
        A class that processes a query and optionally an input file to generate a final formatted answer.
        Methods
        -------
        __call__(query: str, input_file_name: str = None) -> Tuple[List[Any], str]:
            Executes the agent pipeline to process the query and input file, 
            returning intermediate answers and a final formatted answer.
    """

    def __call__(self, query: str, input_file_name: str = None) -> Tuple[List[Any], str]:
        """
        Executes the main logic of the agent by processing a query and optionally an input file, 
        and returns intermediate answers along with a formatted final answer.

        Args:
            query (str): The query string that specifies the task or information required.
            input_file_name (str, optional): The name of the input file to be used for processing. 
                                            Defaults to None.

        Returns:
            Tuple[List[Any], str]: A tuple containing:
                - A list of intermediate answers generated by the agent's basic tooling.
                - A final formatted answer string that adheres to the query's requirements and rules.
        """
        
        logging.debug(f"Using query: {query}")
        logging.debug(f"Using input_file: {input_file_name}")

        agent_basic_tooling = AgentBasicTooling()
        intermediate_answers, intermediate_answer = agent_basic_tooling(
            query=query,
            input_file=input_file_name
        )

        logging.debug(f"Obtained tooling agent answer : {intermediate_answer}")

        formatting_prompt = f"""
            <role>
                You are an information analyst agent which formats a certain input to a message that respects perfectly the query.
            </role>
            <task>
                We will provide you a query and an intermediate answer. Format the answer so that it fits perfectly towards the output expected by the query and aligned with the rules we provide.
            </task>
            <query>
                {query}
            </query>
            <intermediate_answer>
                {intermediate_answer}
            </intermediate_answer>
            <rules>
                * If you are asked for a number, provide just the numeric value respecting the formatting if specified.
                * If you are asked or using a currency value, do not use the currency symbol - use just the number.
                * If you are asked for a string provide the string without quotes.
                * When you are asked for a list, provide the list in a comma separated format without any quotes. Add a space after each comma.
                * Do not add any trailing spaces and new lines.
            </rules>        
        """

        final_answer_llm = get_final_answer_LLM()
        final_answer_content = final_answer_llm.invoke([HumanMessage(content=formatting_prompt)]).content

        logging.debug(f"Obtained final answer : {final_answer_content}")

        return intermediate_answers, final_answer_content
